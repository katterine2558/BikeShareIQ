# üö¥‚Äç‚ôÄÔ∏è CycleCast ‚Äî Bike-Share Demand Forecasting (EDA ‚Üí PolyReg ‚Üí Lasso)

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.x-orange)
![Made with Jupyter](https://img.shields.io/badge/Made%20with-Jupyter-9cf)
![License](https://img.shields.io/badge/License-MIT-green)

> Predicci√≥n **interpretable** de la demanda de bicicletas compartidas a partir de clima, calendario y hora del d√≠a. Pipeline completo: **EDA ‚Üí limpieza ‚Üí modelado (Regresi√≥n Polin√≥mica grado 3 & Lasso) ‚Üí evaluaci√≥n ‚Üí interpretabilidad**.

---

## ‚ú® TL;DR
- Dos enfoques de regresi√≥n (Polin√≥mica g3 y Lasso) para estimar la variable objetivo `cnt` (demanda).  
- Incluye reporte de EDA, divisi√≥n reproducible train/test, m√©tricas (RMSE/MAE/R¬≤) y an√°lisis de coeficientes para explicar los factores que m√°s pesan en la predicci√≥n.

---

## üß† ¬øQu√© hay aqu√≠?
- **EDA**: perfilamiento con reporte HTML; duplicados, correlaciones (`temp`‚Üî`atemp`), valores at√≠picos en `hum` y chequeo de categor√≠as (`weekday`, `weathersit`).  
- **Preprocesamiento**: eliminaci√≥n de duplicados, dummies para categ√≥ricas, features de **franja horaria** (`time_of_day`), etc.
- **Modelos**: 
  - **Regresi√≥n Polin√≥mica (grado 3)** como baseline no lineal.
  - **Lasso** para regularizar y **seleccionar variables** (coeficientes exactos en cero).
- **Evaluaci√≥n**: RMSE / MAE / R¬≤ (tabla comparativa).
- **Interpretabilidad (Lasso)**: importancia de `temp`/`atemp`, efecto negativo de `hum`, categor√≠as √∫tiles en `weathersit`, y propuesta de simplificar `weekday` a **fin de semana vs. d√≠a h√°bil**.

---

## üìÇ Estructura sugerida

```text
cyclecast/
‚îú‚îÄ data/                     # dataset (no incluido)
‚îú‚îÄ notebooks/
‚îÇ  ‚îî‚îÄ PML-Proyecto-PT1_V2.ipynb
‚îú‚îÄ reports/
‚îÇ  ‚îî‚îÄ PML-Proyecto-PT1_V2.html
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ features.py
‚îÇ  ‚îú‚îÄ train_lasso.py
‚îÇ  ‚îî‚îÄ train_poly.py
‚îú‚îÄ requirements.txt
‚îî‚îÄ README.md
````
## ‚öôÔ∏è Reproducir

> Requisitos: **Python 3.10+** y `git`. El dataset no est√° incluido.

1) **Clona el repo**
```bash
git clone https://github.com/<tu-usuario>/<tu-repo>.git
cd <tu-repo>
```
2) **Crea y activa un entorno virtual**
```bash
python -m venv .venv
source .venv/bin/activate
```
3) **Instala dependencias**
```bash
pip install -r requirements.txt
# Si no tienes requirements.txt, usa:
# pip install pandas scikit-learn matplotlib seaborn ydata-profiling
```
4) **Ubica el dataset**
``` bash
Coloca tu CSV en data/ (por ejemplo: data/bike_sharing.csv).
```
5) **Ejecuta el notebook**

```bash
python -m notebook
```
